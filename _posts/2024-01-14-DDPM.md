---
title: "[Paper Review] DDPM"
date: 2024-01-09 16:30:11 +/-0000
categories: [Paper Review, GenerativeAI]
tags: [gan, ai, generative, math]   
math: true  # TAG names should always be lowercase
typora-root-url: ../
---



# Denosing Diffusion Probability Model

## Introduction

![1](/assets/img/DDPM/1.png)

Diffusion 모델은 variational inference을 사용해 훈련된 Markov Chain이다. 일정 시간 뒤에 데이터와 일치하는 sample을 생성하기 위해 데이터에 노이즈를 점차적으로 추가하는 Markov Chain을 Reverse하는 과정을 학습한다. Gaussian Noise로 가정할 경우, Reverse process 역시 conditional Gaussian으로 설정할 수 있으며, Neural Network를 파라미터화 할 수 있다.

DDPM을 소개하기 전에, 기본적인 Diffusion Model에 대해 소개를 하고 넘어가자.

## Background

#### Foward Process

![foward](/assets/img/DDPM/foward.png)

**Diffusion모델이 다른 latent variable 모델과 구별되는 점은 foward process라 불리는 $q(x_{1:T}|x_0)$이다.** 이 과정에서는 이미지를 Gaussian Noise를 점차 입혀서 $x\_{0}$ 부터 $x\_{t}$까지 만든다. $q(x_{1:T}\|x_0)$   는 Gaussian Noise를 variance schedule인 $\beta_1$ ~ $\beta_T$에 따라 점진적으로 추가하는 Markov chain으로 고정된다.
$$
q(x_{1:T}|x_0) = \prod_{t=1}^{T}q(x_t|x_{t-1})
$$

$q(x_t\|x\_{t-1})$는 이전 time step인 $x\_{t-1}$에 따라 Markov chain에 의해 결정될 $x_t$의 확률분포를 의미한다. Gaussian 분포로 가정하였기 때문에, $x_t$를 알기 위해서는 mean $\mu_t$와 std $\sigma_t$를 알아야 하며 $q(x_{t}\|x_{t-1}) = N(x_{t}; \mu_t,  \sigma_tI)$ 로 표현할 수 있다.

여기서, $x_t$의 mean과 std는 $x_{t-1}$로 다음과 같이 나타낼 수 있다.

- $\mu_t = \sqrt{1-\beta_t}x\_{t-1}$ ,  $\sigma_t = \beta_{t}$

즉 $q(x_t\|x_{t-1})$는 다음과 같이 표현된다.

$$
q(x_{t}|x_{t-1}) = N(x_{t}; \sqrt{1-\beta_{t}}x_{t-1}, \beta_{t}I)
$$



#### Reverse Process

Diffusion모델에서 reverse process는 결합확률분포인 $p\_\theta(x_{0:T})$이다. 이는 $p(x_T) = N(x_T;0, I)$에서 시작하는 Gaussian으로 학습되는 Markov chain으로 정의된다.

$$
p_\theta(x_{0:T}) := p(x_T)\prod_{t=1}^{T}p_\theta(x_{t-1}|x_t)
$$

여기서 $p_\theta(x_{t-1}\|x_t)$는 $x_t$에 대한 $x_{t-1}$의 확률 분포를 의미하며 다음과 같이 구할 수 있다.

$$
p_\theta(x_{t-1}|x_t):= N(x_{t-1};\mu_\theta(x_t, t), \Sigma_{\theta}(x_t, t))
$$



$$
\left.\begin{matrix} p(x_T) = N(x_T; 0,I)
\\ p(x_{t-1}|x_t) = N(x_{t-1}; \mu_{\theta}(x_t,t), \sigma_t^2I)
\end{matrix}\right\} \;\; \mapsto \;\; p_{\theta}(x_{0:T}) = p(x_T)\prod_{t=1}^T{p_{\theta}(x_{t-1} | x_t})
$$



학습은 Negative log likelihood의 variational bound를 최적화하는 방향으로 진행된다.


$$
E_{q(x_0)}[- \log{p_\theta(x_0)} ]\leq E_{q}\left [-\log{\frac{p_\theta(x_{0:T})}{q(x_{1:T}|x_0)}}\right ] = E_{q}\left [-log\;p(x_T) - \sum_{t\geq 1} \log{\frac{p_\theta(x_{t-1}|x_t)}{q(x_{t}|x_{t-1})}}\right ] =:L
$$


여기서 Negative log likelihood란 모델이 생성한 확률분포가 실제 데이터의 확률분포와 얼마나 일치하는지 측정하는 손실함수이다. variational bound는  KL Divergence를 활용하여 모델이 생성한 분포와 실제 데이터의 분포 간의 차이를 최소화하는 것에 기반한다. 

Foward process에서 $\beta_t$는 하이퍼파라미터로 값을 유지하거나, reparameterization을 통해 학습할 수 있다. $\beta_t$가 작을 때, Foward($q$)와 Reverse($p$) Process는 같은 함수 형태를 띄기 때문에 Reverse Process($p$)의 표현은 부분적으로 $p_\theta (x\_{t-1} \| x\_t)$의 Gaussian 조건부 선택에 의해 보장받는다.

> reparameterization이란 주로 sampling 연산을 미분할 수 없어서 역전파를 사용하지 못하는 문제를 해결하기 위해 사용한다. sampling 과정을 바로 미분할 수 없으니, sampling 연산 과정의 파라미터를 바꿔서 미분이 가능하도록 변환하는 기법이다. ~~reparameterization에 대해 필자는 이 블로그를 통해 공부하였다. 참고가 되었음을 바라며 링크를 첨부한다. [링크](https://velog.io/@nochesita/%EB%94%A5%EB%9F%AC%EB%8B%9D-Reparameterization-Trick)~~

> 위 문단을 조금 더 풀어 설명하자면, $\beta_t$값이 작아질수록 두 process 과정은 비슷해진다. $p_\theta (x_{t-1} \| x_t)$라는 조건부 확률은 파라미터 $\theta$에 의해 결정되며 Gaussian 분포를 따른다.



Foward process는 다음과 같이 표현할 수 있다.

 $\alpha_t := 1-\beta_t$,  $\overline{\alpha}\_t := \prod_{t}^{s=1}\alpha_s$ 일때,


$$
q(x_{t}|x_{0}) = N(x_{t}; \sqrt{\overline{\alpha}_{t}}x_{0}, (1-\overline{\alpha}_{t})I)
$$



**가우시안 nosie를 순차적으로 적용하기 때문에 원하는 타임 step으로 바로 이동할 수도 있지 않을까?** → <span style=' background-color: #F7DDBE'>**DDPM**</span>

샘플링을 통해 $x_t = \sqrt{\bar{\alpha}\_t}x_0 + \sqrt{(1-\bar{\alpha}_t)}\epsilon$ 이라는 식을 얻을 수 있다. 즉 원하는 step으로 바로 건너뛰어 $x_t$를 얻을 수 있다는 것이다.

stochastic gradient descent(확률적 경사하강법)을 이용해 최적화하면 효율적인 학습이 가능하다.

variance를 줄여 L을 다음과 같이 쓸 수 있다. 



$$
L = E_q \left [ \underbrace{D_{KL}(q(x_T|x_0) || p(x_T)}_{L_T}  + \sum_{t > 1}\underbrace{D_{KL}(q(x_{t-1}|x_t, x_0)||p_\theta(x_{t-1}|x_t))}_{L_{t-1}} \underbrace{- \log{p_\theta(x_0|x_1)}}_{L_0} \right] \tag {5}
$$


수식 (5)는 추후 자주 언급되니 기억해놓도록 하자.

수식(5)에서 사용한 KL divergence는 Gaussian 간의 비교이다. 그러므로 몬테-카를로 추정 대신, 닫힌 수식 형태를 이용한 라오-블랙웰 정리를 이용해 계산할 수 있다.

> 닫힌 형식이란, 다른 수학적 표현이나 무한 합이나 적분 없이 특정한 형태로 명확하게 나타낼 수 있거나 특정 값이 직접 계산되어 나오는 형태을 말한다.

> [몬테 카를로 추정 (Monte-carlo estimation)](https://ko.wikipedia.org/wiki/%EB%AA%AC%ED%85%8C%EC%B9%B4%EB%A5%BC%EB%A1%9C_%EB%B0%A9%EB%B2%95)
>
> Random Sampling을 반복하여 함수의 값을 수리적으로 근사하는 알고리즘이다. 계산하려는 값이 닫힌 형식으로 표현되지 않거나 복잡한 경우에 근사적으로 계산하기 위해 사용된다.

> 라오-블랙웰 정리 (Rao Blackwell Theorem)
>
> 어떤 추정량이 있을 때, 충분 통계량에 대한 조건부 기댓값을 취함으로써 더 좋은 추정량을 만들 수 있음을 뜻한다.
>
> $S(X)$ : 추정량, $T(X)$ : 충분통계량, $S^*(X) = \mathbb{E}\left [S(X) \| T(X) \right ]$라고 할때, 다음이 성립한다.
>
> 
> $$
> \mathbb{E}\left [S^*(X) \right ] = \mathbb{E}\left [S(X) \right ]\\
> Var\left [S^*(X) \right ] \leq Var\left [S(X) \right ]
> $$
> 

$L_T$의 경우 $ p(x_T)$는 가우시안으로 가정하고, $q$ 역시 $x_T$는 가우시안 노이즈이기 때문에 두 분포는 거의 일치한다. 즉 KL Divergence는 거의 없다.

$L_{t-1}$의 경우, KL Divergence의 $q(x\_{t-1}\|x_t, x_0)$와 $p\_\theta(x\_{t-1}\|x_t)$는 Normal distributions이다. 



## Diffusion models and Denoising Autoencoders







$$
\mu_\theta(x_t, t) = \frac{1}{\sqrt{1-\beta_t}}\left ( x_t - \frac{\beta_t}{\sqrt{1-\widetilde{\alpha_t}}} \epsilon_\theta(x_t, t) \right )
$$

- $\mu_{\theta}(x_t,t)$는 가우시안 분포로 가정한 denosing model의 평균을 나타낸다.
- $\epsilon_\theta(x_t, t)$는 noise-prediction network를 통해 위 평균을 예측할 수 있다.







## Learning Denoising Model

- Variational Upper Bound를 통해 학습
  
    $$
    E_{q(x_0)}[- \log{p_\theta(x_0)} ]\leq E_{q(x_0)q(x_{1:T}|x_0)}\left [\log{\frac{p_\theta(x_{0:T})}{q(x_{1:T}|x_0)}}\right ] = :L
    $$
    
- **Deep Unsupervised Learning using Nonequilibrium Thermodynamics(2015)**에서
  
    최종 loss는 평균을 구하는 것임을 알 수 있음 (→ Regression과 동일)
    
    - Loss
    
    $$
    L = E_q \left [ D_{KL}(q(x_T|x_0) || p(x_T)  + \sum_{t > 1}{D_{KL}(q(x_{t-1}|x_t, x_0)||p_\theta(x_{t-1}|x_t)) - \log{p_\theta(x_0|x_1)}} \right]
    $$
    
    - tmp
        - 첫번째, p(xT)는 가우시안으로 가정하고, q 역시 xT는 가우시안 노이즈이기 때문에 KL Divergence는 거의 없음
        - 두번째, KL Divergence의 $q(x\_{t-1}\|x_t, x_0)$와 $p\_\theta(x_{t-1}\|x_t)$는 Normal distributions이다.
    
- 위를 간단하게 하면,

$$
L_{simple} = E_{x_0 \sim q(x_0), \epsilon\sim N(0, I), t \sim u(1, T)}\left [ \left\|\epsilon - \epsilon_\theta(\sqrt{\bar{\alpha_t}}x_0 + \sqrt{1 - \bar{\alpha_t}}\epsilon, t\right\|^2 \right ]
$$



이며, 최종적으로 가우시안 모델의 평균을 예측하기 위해서는 스텝 사이의 노이즈를 예측하는 모델을 만들면 되며,

위 loss를 학습시켜 noise predict를 학습시킨다.

매 스텝마다 가우시안 노이즈를 샘플링하고 이미지마다 t에 맞게 노이즈를 더하고, 이를 통해 네트워크가 이떤 노이즈가 더해졌는지 예측하는 방향으로 학습하게 됨.

## Diffusion Parameters

![2](/assets/img/DDPM/2.png)







