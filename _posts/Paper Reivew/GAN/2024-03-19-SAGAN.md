---
title: "[Paper Review] SAGAN - Self Attention GAN"
date: 2024-03-19 20:30:11 +/-0000
categories: [Paper Review, GAN]
tags: [gan, ai, generative, math]   
math: true  # TAG names should always be lowercase
typora-root-url: ../../../
---

[논문 링크](https://arxiv.org/abs/1805.08318)



이번에는 Self-attention 기법을 GAN에 적용한 SAGAN에 대한 논문을 읽어볼까 한다. 



기존의 GAN은 convolution에서 low-resolution feature map의 정보만을 활용해 high-resolution인 detail 요소를 생성한다. 하지만, SAGAN에서는 모든 feature map의 정보를 활용하여 detail 요소를 생성하며, $D$는 멀리 있는 아주 작은 detail까지 서로 일치하는지 확인할 수 있다.



## **Introduction**

이전 GAN들은 텍스쳐로 구분되는 class(하늘, 바다, 풍경 등)에는 좋은 성능을 보이지만, 복잡한 구조를 가진 class(강아지의 털은 잘 표현하지만 발은 잘 그리지 못함)에는 detail적인 부분에서 아쉬운 성능을 보였다. 이는 다른 이미지 영역의 dependency(종속성)를 modeling할 때 convolution에 의존하기 때문이다. 

> Convolution 연산을 할 때, receptive field는 local에 국한되기 때문에(데이터를 감지하는 영역이 작기 때문에) long range dependencies를 처리하기 위해서는 convolution layer를 깊게 쌓아 각 layer를 통과할 때마다 receptive field를 점차 확장시켜 넓은 영역에 대한 정보를 감지해야한다.
>
> **즉, 가벼운 모델로는 처리가 불가능하며, Optimization 알고리즘이 dependency를 감지하는 parameter값을 찾는 게 힘들어지며, 생소한 데이터에 대해 실패할 확률이 크다.**

이러한 문제를 논문에서는 <span style=' background-color: #F7DDBE'>**Self-Attention 기법을 활용하여 long range dependencies를 효과적으로 modeling하는 SAGAN을 제안**한다. </span>어떤 위치에서의 반응을 모든 위치 feature의 가중치 합으로 계산하는데, weight나 attention vector의 계산은 매우 적은 비용으로 가능하다. 

또한, ***network conditioning*(조건)**에 대한 insight를 적용시켰다. $D$에만 적용되었던 spectral normalization 기법을 $G$에도 적용시켜 성능을 향상시켰다.

**Image-Net 데이터셋으로 실험한 결과, Inception score를 36.8에서 52.52로 높이고, Fréchet Inception Distance를 27.62에서 18.65로 줄여 새로운 SOTA를 달성하였다고 한다.**



## Related Work : Attention

원래라면 넘어갔을 Related work section이지만, <span style="color:red;">Attention Model</span>을 GAN에 적용시킨 첫 논문이므로, 짚고 넘어가자

*필자가 작년에 허술하게 [Attention 논문 리뷰](https://hahngyutak.github.io/posts/Transformer/)도 있다..*

### **Attention model**

